{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kZBTeZ7xj8WJTU3C-fKdUMdygUyoaaTa",
      "authorship_tag": "ABX9TyPNEjuOqUmlsAras2rC+sps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nirmal0009/PySpark---Recommendation-System/blob/main/Insurance_Recommendation_System_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Core Recommendation Engine Using Cosine Similarity in PySpark Using Colab Notebook**\n",
        "\n",
        "In this project, we build a recommendation engine using cosine similarity to suggest policies to customers based on their income ranges. PySpark is utilized to handle large datasets efficiently and perform the necessary computations.\n",
        "\n",
        "Here’s a summary of the libraries and their functionalities used:\n",
        "\n",
        "\n",
        "\n",
        "*   **pyspark.sql.SparkSession**: Provides the entry point to interact with Spark and creates DataFrame objects.\n",
        "*   pyspark.sql.functions.col: Allows for column operations such as filtering and selecting specific columns.\n",
        "\n",
        "*   **pyspark.ml.feature.VectorAssembler**: Converts feature columns into a vector format, which is necessary for machine learning algorithms.\n",
        "\n",
        "*   **pyspark.ml.linalg.Vectors**: Provides tools to create dense and sparse vectors required for cosine similarity calculations.\n",
        "*   numpy: Provides support for numerical operations and array handling, though it's not directly used in this particular code.\n",
        "\n",
        "\n",
        "*   **pyspark.sql.functions.collect_list**: Aggregates values into a list, useful for collecting results from grouped data.\n",
        "\n",
        "*   **pyspark.sql.functions.udf**: Allows the creation of user-defined functions to perform custom operations on DataFrame columns.\n",
        "\n",
        "*   **pyspark.sql.types.DoubleType**: Defines the data type for columns that contain double precision floating-point numbers, used for similarity scores.\n",
        "*   **pyspark.sql.functions.col**: Allows for column operations such as filtering and selecting specific columns.\n",
        "\n",
        "\n",
        "*   **pyspark.ml.feature.VectorAssembler**: Converts feature columns into a vector format, which is necessary for machine learning algorithms.\n",
        "\n",
        "*   **pyspark.ml.linalg.Vectors**: Provides tools to create dense and sparse vectors required for cosine similarity calculations.\n",
        "\n",
        "*   **numpy**: Provides support for numerical operations and array handling, though it's not directly used in this particular code.\n",
        "*   pyspark.sql.functions.collect_list: Aggregates values into a list, useful for collecting results from grouped data.\n",
        "\n",
        "\n",
        "\n",
        "*   **pyspark.sql.functions.udf**: Allows the creation of user-defined functions to perform custom operations on DataFrame columns.\n",
        "*   **pyspark.sql.types.DoubleType**: Defines the data type for columns that contain double precision floating-point numbers, used for similarity scores.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This setup efficiently computes similarity scores and recommends policies based on the cosine similarity of income ranges, leveraging the distributed computing power of PySpark."
      ],
      "metadata": {
        "id": "d7WGlxng9Qgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRyzEAcT4JUt",
        "outputId": "a46fdca4-bf6e-4080-9245-6677e3adb4a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488490 sha256=b218b48d3206bb26252925d3e7ecdb79f26d53a750db3c75f56a116b69fcce0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J82RN0OF25lu",
        "outputId": "16a58067-6cc4-44eb-b104-15c14d8ba8c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import collect_list"
      ],
      "metadata": {
        "id": "QtxGrpXheNft"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize a Spark session\n",
        "\n",
        "spark = SparkSession.builder.appName('Dataframe').getOrCreate()"
      ],
      "metadata": {
        "id": "3gMPq_Jz4QIt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use PySpark to read the CSV file from your Google Drive\n",
        "file_path = '/content/drive/MyDrive/Dataset.csv'  # Update this with the actual file path\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows of the dataframe\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0nGoLCv4Y_u",
        "outputId": "6bdb14b6-c15e-49ca-841b-a14d15004c06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+------+--------------+------------+------------+-----------------+----------------------+--------+---------------+----------------+-----------------+-------------------+-------------+----------------------------------+------------------------+---------------+--------------+----------+-----------+--------------------+-------------------------------+----------------------+------------------+------------+-----------------------+------------+----------------+-----------+------------------+\n",
            "|Customer ID|Age|Gender|Marital Status|  Occupation|Income Level|  Education Level|Geographic Information|Location|Behavioral Data|Purchase History|Policy Start Date|Policy Renewal Date|Claim History|Interactions with Customer Service|Insurance Products Owned|Coverage Amount|Premium Amount|Deductible|Policy Type|Customer Preferences|Preferred Communication Channel|Preferred Contact Time|Preferred Language|Risk Profile|Previous Claims History|Credit Score|  Driving Record|Life Events|Segmentation Group|\n",
            "+-----------+---+------+--------------+------------+------------+-----------------+----------------------+--------+---------------+----------------+-----------------+-------------------+-------------+----------------------------------+------------------------+---------------+--------------+----------+-----------+--------------------+-------------------------------+----------------------+------------------+------------+-----------------------+------------+----------------+-----------+------------------+\n",
            "|      84966| 23|Female|       Married|Entrepreneur|       70541| Associate Degree|               Mizoram|   37534|        policy5|      04-10-2018|       08-01-2023|         12-03-2023|            5|                             Phone|                 policy2|         366603|          2749|      1604|      Group|               Email|              In-Person Meeting|             Afternoon|           English|           1|                      3|         728|             DUI| Job Change|          Segment5|\n",
            "|      95568| 26|  Male|       Widowed|     Manager|       54168|        Doctorate|                   Goa|   63304|        policy5|      11-06-2018|       09-06-2020|         06-09-2023|            0|                              Chat|                 policy1|         780236|          1966|      1445|      Group|                Mail|              In-Person Meeting|               Morning|            French|           1|                      2|         792|           Clean| Retirement|          Segment5|\n",
            "|      10544| 29|Female|        Single|Entrepreneur|       73899| Associate Degree|             Rajasthan|   53174|        policy5|      06-05-2021|       09-03-2023|         11-03-2024|            4|                             Email|                 policy3|         773926|          4413|      1612|      Group|               Email|                           Mail|               Evening|            German|           2|                      1|         719|        Accident| Childbirth|          Segment3|\n",
            "|      77033| 20|  Male|      Divorced|Entrepreneur|       63381|Bachelor's Degree|                Sikkim|   22803|        policy5|      09-02-2018|        4/14/2018|         05-04-2023|            5|                              Chat|                 policy2|         787815|          4342|      1817|     Family|                Text|              In-Person Meeting|               Anytime|            French|           3|                      0|         639|             DUI| Job Change|          Segment3|\n",
            "|      88160| 25|Female|     Separated|     Manager|       38794|Bachelor's Degree|           West Bengal|   92858|        policy1|      09-10-2018|       12-02-2022|         09-10-2023|            3|                              Chat|                 policy4|         366506|          1276|       133|     Family|               Email|                           Text|              Weekends|           English|           0|                      3|         720|Major Violations| Childbirth|          Segment2|\n",
            "+-----------+---+------+--------------+------------+------------+-----------------+----------------------+--------+---------------+----------------+-----------------+-------------------+-------------+----------------------------------+------------------------+---------------+--------------+----------+-----------+--------------------+-------------------------------+----------------------+------------------+------------+-----------------------+------------+----------------+-----------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Customer ID','Income Level','Behavioral Data']\n",
        "df = df[columns]\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du9F-u6T4xrE",
        "outputId": "4abaa9d8-4382-4df8-adcc-edbf76d71b41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+---------------+\n",
            "|Customer ID|Income Level|Behavioral Data|\n",
            "+-----------+------------+---------------+\n",
            "|      84966|       70541|        policy5|\n",
            "|      95568|       54168|        policy5|\n",
            "|      10544|       73899|        policy5|\n",
            "|      77033|       63381|        policy5|\n",
            "|      88160|       38794|        policy1|\n",
            "|      60937|       87188|        policy5|\n",
            "|      37676|       94891|        policy3|\n",
            "|      54100|       61003|        policy1|\n",
            "|      30476|      116249|        policy1|\n",
            "|      39071|       49083|        policy3|\n",
            "|      38477|       62099|        policy2|\n",
            "|      38329|      110698|        policy4|\n",
            "|       6580|       90301|        policy5|\n",
            "|      67128|       24648|        policy3|\n",
            "|      34814|      105009|        policy3|\n",
            "|      86048|       29783|        policy1|\n",
            "|      24881|      114236|        policy3|\n",
            "|      24076|      107359|        policy2|\n",
            "|      38654|       49224|        policy5|\n",
            "|      47840|      117264|        policy4|\n",
            "+-----------+------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df = df.groupBy(\"Customer ID\").pivot(\"Behavioral Data\").sum(\"Income Level\").fillna(0)\n",
        "pivot_df.show()"
      ],
      "metadata": {
        "id": "xvMI8gdL7r2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f06fee-7c71-4b7d-8326-5d93cb49e281"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------+-------+-------+-------+\n",
            "|Customer ID|policy1|policy2|policy3|policy4|policy5|\n",
            "+-----------+-------+-------+-------+-------+-------+\n",
            "|      43935|      0| 266631|      0|      0|      0|\n",
            "|       3794| 133591|      0|      0|      0| 139525|\n",
            "|      66176|      0| 182902|      0|      0|      0|\n",
            "|      11033|      0|      0|  35779| 106236|      0|\n",
            "|       9427|      0| 111693|      0|      0|      0|\n",
            "|      75122| 142537|  26899|      0|  84393|      0|\n",
            "|      87462|      0|      0|      0|      0| 122320|\n",
            "|      65478|  41347|      0|      0|      0| 118079|\n",
            "|      89874|      0|  90825|      0| 100429|      0|\n",
            "|      71510| 127793|      0|      0|      0|      0|\n",
            "|       1580|      0| 125419| 105686|      0|      0|\n",
            "|      73683|      0|  52204|      0|      0|      0|\n",
            "|      89878|  37081|      0|      0|      0|      0|\n",
            "|      96853|      0| 113491|      0|      0| 118528|\n",
            "|      71527|      0|      0| 102112|      0|      0|\n",
            "|       3918|      0| 112358| 116143|      0|      0|\n",
            "|      26425|  43813|  39857|      0|      0|      0|\n",
            "|      48510|      0|      0|  35122|      0|      0|\n",
            "|      87338|      0| 144474|      0|      0|      0|\n",
            "|      48398|  24489|      0|      0|      0|      0|\n",
            "+-----------+-------+-------+-------+-------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the pivoted DataFrame into feature vectors as its required for cosine similarity\n",
        "assembler = VectorAssembler(inputCols=pivot_df.columns[1:], outputCol=\"features\")\n",
        "pivot_df = assembler.transform(pivot_df)\n",
        "pivot_df.select(\"features\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JmPNbmLcPET",
        "outputId": "e1739278-3247-40e5-edfd-4d3a439992d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+\n",
            "|features                          |\n",
            "+----------------------------------+\n",
            "|(5,[1],[266631.0])                |\n",
            "|(5,[0,4],[133591.0,139525.0])     |\n",
            "|(5,[1],[182902.0])                |\n",
            "|(5,[2,3],[35779.0,106236.0])      |\n",
            "|(5,[1],[111693.0])                |\n",
            "|[142537.0,26899.0,0.0,84393.0,0.0]|\n",
            "|(5,[4],[122320.0])                |\n",
            "|(5,[0,4],[41347.0,118079.0])      |\n",
            "|(5,[1,3],[90825.0,100429.0])      |\n",
            "|(5,[0],[127793.0])                |\n",
            "|(5,[1,2],[125419.0,105686.0])     |\n",
            "|(5,[1],[52204.0])                 |\n",
            "|(5,[0],[37081.0])                 |\n",
            "|(5,[1,4],[113491.0,118528.0])     |\n",
            "|(5,[2],[102112.0])                |\n",
            "|(5,[1,2],[112358.0,116143.0])     |\n",
            "|(5,[0,1],[43813.0,39857.0])       |\n",
            "|(5,[2],[35122.0])                 |\n",
            "|(5,[1],[144474.0])                |\n",
            "|(5,[0],[24489.0])                 |\n",
            "+----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a UDF for cosine similarity - To apply cosine similarity function within Spark DataFrame operations.\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType"
      ],
      "metadata": {
        "id": "qm12G8RBfuVS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity - To measure similarity between clients.\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_a = np.linalg.norm(vec1)\n",
        "    norm_b = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm_a * norm_b)\n",
        "\n",
        "\n",
        "#Apply cosine similarity function within Spark DataFrame operations. (UDF - User defind function)\n",
        "cosine_similarity_udf = udf(lambda x, y: float(cosine_similarity(x.toArray(), y.toArray())), DoubleType())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dv0DXKvNgBa_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross joining to compute similarity between all clients\n",
        "cross_joined_df = pivot_df.alias(\"df1\").crossJoin(pivot_df.alias(\"df2\"))\n",
        "\n",
        "cross_joined_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plIputwRhMLS",
        "outputId": "1d2ecba8-0971-4554-eb2b-b4fba79cdfaa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------+-------+-------+-------+------------------+-----------+-------+-------+-------+-------+-------+--------------------+\n",
            "|Customer ID|policy1|policy2|policy3|policy4|policy5|          features|Customer ID|policy1|policy2|policy3|policy4|policy5|            features|\n",
            "+-----------+-------+-------+-------+-------+-------+------------------+-----------+-------+-------+-------+-------+-------+--------------------+\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      43935|      0| 266631|      0|      0|      0|  (5,[1],[266631.0])|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|       3794| 133591|      0|      0|      0| 139525|(5,[0,4],[133591....|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      66176|      0| 182902|      0|      0|      0|  (5,[1],[182902.0])|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      11033|      0|      0|  35779| 106236|      0|(5,[2,3],[35779.0...|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|       9427|      0| 111693|      0|      0|      0|  (5,[1],[111693.0])|\n",
            "+-----------+-------+-------+-------+-------+-------+------------------+-----------+-------+-------+-------+-------+-------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding similarity column using cosine_similarity_udf lambda func\n",
        "similarity_df = cross_joined_df.withColumn(\n",
        "    \"similarity\",\n",
        "    cosine_similarity_udf(col(\"df1.features\"), col(\"df2.features\"))).filter(col(\"df1.Customer ID\") != col(\"df2.Customer ID\"))\n",
        "\n",
        "similarity_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ9Zc8LyhWIm",
        "outputId": "96017c5d-ec4a-483f-fbc6-5375ad3c581d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------+-------+-------+-------+-------+------------------+-----------+-------+-------+-------+-------+-------+--------------------+------------------+\n",
            "|Customer ID|policy1|policy2|policy3|policy4|policy5|          features|Customer ID|policy1|policy2|policy3|policy4|policy5|            features|        similarity|\n",
            "+-----------+-------+-------+-------+-------+-------+------------------+-----------+-------+-------+-------+-------+-------+--------------------+------------------+\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|       3794| 133591|      0|      0|      0| 139525|(5,[0,4],[133591....|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      66176|      0| 182902|      0|      0|      0|  (5,[1],[182902.0])|               1.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      11033|      0|      0|  35779| 106236|      0|(5,[2,3],[35779.0...|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|       9427|      0| 111693|      0|      0|      0|  (5,[1],[111693.0])|               1.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      75122| 142537|  26899|      0|  84393|      0|[142537.0,26899.0...|0.1602877355118727|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      87462|      0|      0|      0|      0| 122320|  (5,[4],[122320.0])|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      65478|  41347|      0|      0|      0| 118079|(5,[0,4],[41347.0...|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      89874|      0|  90825|      0| 100429|      0|(5,[1,3],[90825.0...|0.6707535798482069|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      71510| 127793|      0|      0|      0|      0|  (5,[0],[127793.0])|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|       1580|      0| 125419| 105686|      0|      0|(5,[1,2],[125419....|0.7647008692489015|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      73683|      0|  52204|      0|      0|      0|   (5,[1],[52204.0])|               1.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      89878|  37081|      0|      0|      0|      0|   (5,[0],[37081.0])|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      96853|      0| 113491|      0|      0| 118528|(5,[1,4],[113491....|  0.69159294230764|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      71527|      0|      0| 102112|      0|      0|  (5,[2],[102112.0])|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|       3918|      0| 112358| 116143|      0|      0|(5,[1,2],[112358....|0.6952985436612387|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      26425|  43813|  39857|      0|      0|      0|(5,[0,1],[43813.0...|0.6729223399944093|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      48510|      0|      0|  35122|      0|      0|   (5,[2],[35122.0])|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      87338|      0| 144474|      0|      0|      0|  (5,[1],[144474.0])|               1.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|      48398|  24489|      0|      0|      0|      0|   (5,[0],[24489.0])|               0.0|\n",
            "|      43935|      0| 266631|      0|      0|      0|(5,[1],[266631.0])|       6466|      0|      0|  62186|      0|      0|   (5,[2],[62186.0])|               0.0|\n",
            "+-----------+-------+-------+-------+-------+-------+------------------+-----------+-------+-------+-------+-------+-------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recommend policies\n",
        "def recommend_policies(client_id):\n",
        "    # Listing out the number of most similar clients where similarity score is considered to be greater than 0.5 (flexible)\n",
        "    similar_clients = similarity_df.filter((col(\"df1.Customer ID\") == client_id) & (col(\"similarity\") > 0.5))\\\n",
        "                               .select(col(\"df2.Customer ID\")).rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "    # Filtering the dataframe with the similar clients\n",
        "    similar_clients_policies = df.filter(col(\"Customer ID\").isin(similar_clients))\n",
        "\n",
        "    # Excluding policies that the input client already has\n",
        "    existing_policies = df.filter(col(\"Customer ID\") == client_id).select(\"Behavioral Data\").rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "    #Recommending the missing policies as per similar client's suggestion\n",
        "    recommendations = similar_clients_policies.filter(~col(\"Behavioral Data\").isin(existing_policies)).select(\"Behavioral Data\").distinct()\n",
        "\n",
        "    # Return recommended policies\n",
        "    return recommendations.rdd.flatMap(lambda x: x).collect()"
      ],
      "metadata": {
        "id": "NFQXJaimkpmQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_policies(43935)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfj_kJRh0fx1",
        "outputId": "5980e011-56bb-406e-cf21-b4c89517d7de"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['policy1', 'policy5', 'policy4', 'policy3']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## THANK YOU"
      ],
      "metadata": {
        "id": "lVT3s85s9AVI"
      }
    }
  ]
}